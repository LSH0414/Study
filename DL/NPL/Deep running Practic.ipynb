{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 딥러닝 학습 방법 \n",
    "\n",
    "## 손실 함수, 옵티마이저, 에포크의 개념 확인하기"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 손실함수\n",
    "\n",
    "손실 함수는 실제값과 예측값 차이를 수치화 해주는 함수. 회구에서는 평균 오차 제곱, 분류 문제에서는 크로스 엔트로피를 주로 손실 함수로 사용한다.\n",
    "\n",
    "\n",
    " #### MSE(Mean Squared Error, MSE)\n",
    " - 평균 오차 제곱. 연속형 변수를 예측할 때 사용.  \n",
    "(딥 러닝 자연어 처리는 대부분 분류 문제이므로 크로스 엔트로피 함수를 주로 사용함.)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.compile(optimizer='adam', loss='mse', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.compile(optimizer='adam', loss=tf.keras.losses.MeanSquaredError(), metrics=['mse'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 크로스 엔트로피\n",
    "- 이진 크로스 엔트로피 (Binary) - 이진 분류의 경우 binary cross-entropy를 사용함. 로지스틱 회귀에서 사용하던 손실 함수."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])  \n",
    "\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer='adam', metrics=['acc'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 카테고리컬 크로스 엔트로피 (Categorical) - 출력층에 소프트 맥스 함수를 사용하는 다중 클래스 분류 일 경우 사용."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "\n",
    "model.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer='adam', metrics=['acc'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 레이블에 대한 원-핫 인코딩을 생략하고, 정수값을 가진 레이블에 대해서 다중 클래스 분류를 수행할 경우 아래와 같이 실행"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "\n",
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(), optimizer='adam', metrics=['acc'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 그 외 손실 함수\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/losses"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 옵티 마이저\n",
    "\n",
    "### Batch-Size"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "손실 함수의 값을 줄여나가면서 학습하는 방법은 어떤 옵티마이저를 사용하느냐에 따라 달라집니다. 여기서 배치(Batch)라는 개념에 대한 이해가 필요합니다. 배치는 가중치 등의 매개 변수의 값을 조정하기 위해 사용하는 데이터의 양을 말합니다. 전체 데이터를 가지고 매개 변수의 값을 조정할 수도 있고, 정해준 양의 데이터만 가지고도 매개 변수의 값을 조정할 수 있습니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 배치 경사 하강법\n",
    "옵티마이저 중 하나로 오차를 구할 때 전체 데이터를 고려. 딥 러닝에서 한 번의 훈련 단위를 에포크라 하는데, 배치 경사 하강법에서 한 번의 에포크에 모든 매개변수 업데이를 단 한 번 수행함. 배치 경사 하강법은 모든 데이터를 고려해서 학습하므로 한 번의 매개변수 업데이트에 시간이 오래걸리며, 메모리를 크게 요구하는 단점이 있음."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.fit(X_train, y_train, batch_size=len(X_train))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 배치 크기가 1인 확률적 경사 하강법\n",
    "매개변수 값 조정시 전체 데이터가 아닌 랜덤으로 선택한 하나의 데이터에 대해서만 계산하는 방법. 더 적은 데이터를 사용하므로 속도는 빠름. 단, 매개변수의 변경폭이 불안정하고 정확도가 배치 경사 하강법보다 낮을 수 있음"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.fit(X_train, y_train, batch_size=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 미니 배치 경사 하강법\n",
    "배치 크기를 지정하여 데이터의 개수만큼에 대해서 계산하여 매개변수의 값을 조정하는 방법. 배치 경사 하강법 보다 빠르고 확률적 경사 하강법 보다는 정확도가 좋다는 점에서 가장 많이 사용되는 경사 하강법. 배치 크기는 일반적으로 2의 n제곱에 해당하는 숫자로 선택하는 것이 보편적. batch_size를 설정하지 않을 경우 기본인 32."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.fit(X_train, y_train, batch_size=128)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 옵티마이저"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 모멘텀\n",
    "모멘텀(Momentum)은 관성이라는 물리학의 법칙을 응용한 방법입니다. 모멘텀 경사 하강법에 관성을 더 해줍니다. 모멘텀은 경사 하강법에서 계산된 접선의 기울기에 한 시점 전의 접선의 기울기값을 일정한 비율만큼 반영합니다. 이렇게 하면 마치 언덕에서 공이 내려올 때, 중간에 작은 웅덩이에 빠지더라도 관성의 힘으로 넘어서는 효과를 줄 수 있습니다.\n",
    "  \n",
    "![image.png](attachment:image.png)\n",
    "  \n",
    "\n",
    "전체 함수에 걸쳐 최소값을 글로벌 미니멈(Global Minimum) 이라고 하고, 글로벌 미니멈이 아닌 특정 구역에서의 최소값인 로컬 미니멈(Local Minimum) 이라고 합니다. 로컬 미니멈에 도달하였을 때 글로벌 미니멈으로 잘못 인식하여 탈출하지 못하였을 상황에서 모멘텀. 즉, 관성의 힘을 빌리면 값이 조절되면서 현재의 로컬 미니멈에서 탈출하고 글로벌 미니멈 내지는 더 낮은 로컬 미니멈으로 갈 수 있는 효과를 얻을 수도 있습니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.keras.optimizers.SGD(lr=0.01, momentum=0.9)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 아다그라드\n",
    "매개변수들은 각자 의미하는 바가 다른데, 모든 매개변수에 동일한 학습률(learning rate)을 적용하는 것은 비효율적입니다. 아다그라드는 각 매개변수에 서로 다른 학습률을 적용시킵니다. 이때 변화가 많은 매개변수는 학습률이 작게 설정되고 변화가 적은 매개변수는 학습률을 높게 설정시킵니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.keras.optimizers.Adagrad(lr=0.01, epsilon=1e-6)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 알엠에스프롭\n",
    "아다그라드는 학습을 계속 진행한 경우에는, 나중에 가서는 학습률이 지나치게 떨어진다는 단점이 있는데 이를 다른 수식으로 대체하여 이러한 단점을 개선하였습니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-06)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. 아담\n",
    "아담은 알엠에스프롭과 모멘텀 두 가지를 합친 듯한 방법으로, 방향과 학습률 두 가지를 모두 잡기 위한 방법입니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 사용 방법\n",
    "-  상세 사용법 : https://www.tensorflow.org/api_docs/python/tf/keras/optimizers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adam = tf.keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['acc'])\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 에포크, 배치 크기, 이터레이션 or 스탭\n",
    "```\n",
    "- 에포크 : 에포크란 인공 신경망에서 전체 데이터에 대해서 순전파와 역전파가 끝난 상태를 말합니다. 전체 데이터를 하나의 문제지에 비유한다면 문제지의 모든 문제를 끝까지 다 풀고, 정답지로 채점을 하여 문제지에 대한 공부를 한 번 끝낸 상태를 말합니다.\n",
    "\n",
    "만약 에포크가 50이라고 하면, 전체 데이터 단위로는 총 50번 학습합니다. 문제지에 비유하면 문제지를 50번 푼 셈입니다. 이 에포크 횟수가 지나치거나 너무 적으면 앞서 배운 과적합과 과소적합이 발생할 수 있습니다.\n",
    "\n",
    "- 배치 크기 : 배치 크기는 몇 개의 데이터 단위로 매개변수를 업데이트 하는지를 말합니다. 현실에 비유하면 문제지에서 몇 개씩 문제를 풀고나서 정답지를 확인하느냐의 문제입니다. 사람은 문제를 풀고 정답을 보는 순간 부족했던 점을 깨달으며 지식이 업데이트 된다고 하였습니다. 기계 입장에서는 실제값과 예측값으로부터 오차를 계산하고 옵티마이저가 매개변수를 업데이트합니다. 여기서 중요한 포인트는 업데이트가 시작되는 시점이 정답지/실제값을 확인하는 시점이라는 겁니다.\n",
    "\n",
    "사람이 2,000 문제가 수록되어있는 문제지의 문제를 200개 단위로 풀고 채점한다고 하면 이때 배치 크기는 200입니다. 기계는 배치 크기가 200이면 200개의 샘플 단위로 가중치를 업데이트 합니다.\n",
    "\n",
    "여기서 주의할 점은 배치 크기와 배치의 수는 다른 개념이라는 점입니다. 전체 데이터가 2,000일때 배치 크기를 200으로 준다면 배치의 수는 10입니다. 이는 에포크에서 배치 크기를 나눠준 값(2,000/200 = 10)이기도 합니다. 이때 배치의 수를 이터레이션이라고 합니다.\n",
    "\n",
    "- 이터레이션 / 스탭 : 이터레이션이란 한 번의 에포크를 끝내기 위해서 필요한 배치의 수를 말합니다. 또는 한 번의 에포크 내에서 이루어지는 매개변수의 업데이트 횟수이기도 합니다. 전체 데이터가 2,000일 때 배치 크기를 200으로 한다면 이터레이션의 수는 총 10입니다. 이는 한 번의 에포크 당 매개변수 업데이트가 10번 이루어진다는 것을 의미합니다. 배치 크기가 1인 확률적 경사 하강법을 이 개념을 가지고 다시 설명하면 배치 크기가 1이므로 모든 이터레이션마다 하나의 데이터를 선택하여 경사 하강법을 수행합니다. 이터레이션은 스텝(Step)이라고 부르기도 함.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3611c2ce1468e061070d489fcefa13c4acc38f8e18ef6c6adb379009ca0f1e66"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
