{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-06 21:31:10.432450: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "for i in range(6):\n",
    "    lst = list(range(i, i+4))\n",
    "\n",
    "    X.append(list(map(lambda c: [c/10], lst)))\n",
    "    Y.append((i+4)/10)\n",
    "\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-06 21:36:01.673806: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn (SimpleRNN)      (None, 10)                120       \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 131\n",
      "Trainable params: 131\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(units=10, return_sequences=False, input_shape=[4,1]),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer = 'adam', loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fefbaa700d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y, epochs=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 900ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.9154298]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.array([[[0.6], [0.7], [0.8], [0.9]]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_1 (SimpleRNN)    (None, 4, 10)             120       \n",
      "                                                                 \n",
      " simple_rnn_2 (SimpleRNN)    (None, 4, 10)             210       \n",
      "                                                                 \n",
      " simple_rnn_3 (SimpleRNN)    (None, 4, 10)             210       \n",
      "                                                                 \n",
      " simple_rnn_4 (SimpleRNN)    (None, 10)                210       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 761\n",
      "Trainable params: 761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(units=10, return_sequences=True, input_shape=[4,1]),\n",
    "    tf.keras.layers.SimpleRNN(units=10, return_sequences=True, input_shape=[4,1]),\n",
    "    tf.keras.layers.SimpleRNN(units=10, return_sequences=True, input_shape=[4,1]),\n",
    "    tf.keras.layers.SimpleRNN(units=10, return_sequences=False, input_shape=[4,1]),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer = 'adam', loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fef9cba2a50>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y, epochs=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 643ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.91955835]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.array([[[0.6], [0.7], [0.8], [0.9]]]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.79664655]\n",
      " [0.         0.88735637]\n",
      " [0.         0.30276085]\n",
      " [0.         0.3329574 ]\n",
      " [0.         0.20408078]\n",
      " [0.         0.12985826]\n",
      " [0.         0.92771967]\n",
      " [1.         0.85466793]\n",
      " [0.         0.4072755 ]\n",
      " [0.         0.73875575]\n",
      " [0.         0.23577355]\n",
      " [0.         0.78248381]\n",
      " [0.         0.51616819]\n",
      " [0.         0.01394269]\n",
      " [0.         0.61889164]\n",
      " [0.         0.64901141]\n",
      " [0.         0.1923458 ]\n",
      " [0.         0.81740062]\n",
      " [0.         0.33182417]\n",
      " [0.         0.40574117]\n",
      " [0.         0.66921988]\n",
      " [0.         0.4278286 ]\n",
      " [0.         0.64447494]\n",
      " [0.         0.42278437]\n",
      " [0.         0.73727395]\n",
      " [0.         0.42018455]\n",
      " [0.         0.27322182]\n",
      " [0.         0.48537113]\n",
      " [0.         0.44271942]\n",
      " [0.         0.98480916]\n",
      " [0.         0.53585025]\n",
      " [0.         0.35317187]\n",
      " [0.         0.17981118]\n",
      " [0.         0.59603238]\n",
      " [0.         0.5345138 ]\n",
      " [0.         0.55863505]\n",
      " [0.         0.92138532]\n",
      " [0.         0.81508885]\n",
      " [0.         0.93115672]\n",
      " [0.         0.64337036]\n",
      " [0.         0.31248436]\n",
      " [0.         0.14056069]\n",
      " [0.         0.93119815]\n",
      " [0.         0.55063465]\n",
      " [0.         0.56597233]\n",
      " [0.         0.1891098 ]\n",
      " [0.         0.99112429]\n",
      " [0.         0.22589639]\n",
      " [0.         0.66325416]\n",
      " [0.         0.33423028]\n",
      " [0.         0.95187307]\n",
      " [0.         0.29279773]\n",
      " [0.         0.5314313 ]\n",
      " [0.         0.01785118]\n",
      " [0.         0.08566003]\n",
      " [0.         0.78390906]\n",
      " [0.         0.75990911]\n",
      " [0.         0.04500989]\n",
      " [0.         0.94578013]\n",
      " [0.         0.24011371]\n",
      " [0.         0.70217972]\n",
      " [0.         0.38868558]\n",
      " [0.         0.01683337]\n",
      " [0.         0.47414594]\n",
      " [0.         0.85214148]\n",
      " [1.         0.60483125]\n",
      " [0.         0.91895983]\n",
      " [0.         0.24317395]\n",
      " [0.         0.30203436]\n",
      " [0.         0.00567915]\n",
      " [0.         0.77671278]\n",
      " [0.         0.09103339]\n",
      " [0.         0.33799538]\n",
      " [0.         0.70207972]\n",
      " [0.         0.46886122]\n",
      " [0.         0.94584109]\n",
      " [0.         0.24593981]\n",
      " [0.         0.72192684]\n",
      " [0.         0.60142474]\n",
      " [0.         0.75511776]\n",
      " [0.         0.22139565]\n",
      " [0.         0.06758887]\n",
      " [0.         0.31546577]\n",
      " [0.         0.79475402]\n",
      " [0.         0.411032  ]\n",
      " [0.         0.66564053]\n",
      " [0.         0.43550356]\n",
      " [0.         0.0561363 ]\n",
      " [0.         0.79768816]\n",
      " [0.         0.82512752]\n",
      " [0.         0.85510944]\n",
      " [0.         0.29461833]\n",
      " [0.         0.78807051]\n",
      " [0.         0.02710842]\n",
      " [0.         0.12745476]\n",
      " [0.         0.96382074]\n",
      " [0.         0.89356159]\n",
      " [0.         0.47073503]\n",
      " [0.         0.05816679]\n",
      " [0.         0.7764374 ]] 0.5169298726530501\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "Y = []\n",
    "for i in range(3000):\n",
    "    lst = np.random.rand(100)\n",
    "    idx = np.random.choice(100, 2, replace=False)\n",
    "    zeros = np.zeros(100)\n",
    "    zeros[idx] = 1\n",
    "    X.append(np.array(list(zip(zeros,lst))))\n",
    "    Y.append(np.prod(lst[idx]))\n",
    "\n",
    "print(X[0], Y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_5 (SimpleRNN)    (None, 100, 30)           990       \n",
      "                                                                 \n",
      " simple_rnn_6 (SimpleRNN)    (None, 30)                1830      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 31        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,851\n",
      "Trainable params: 2,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(units = 30, return_sequences=True, input_shape = [100,2]),\n",
    "    tf.keras.layers.SimpleRNN(units = 30),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "64/64 [==============================] - 5s 38ms/step - loss: 0.0720 - val_loss: 0.0422\n",
      "Epoch 2/100\n",
      "64/64 [==============================] - 3s 50ms/step - loss: 0.0517 - val_loss: 0.0533\n",
      "Epoch 3/100\n",
      "64/64 [==============================] - 4s 66ms/step - loss: 0.0513 - val_loss: 0.0407\n",
      "Epoch 4/100\n",
      "64/64 [==============================] - 4s 65ms/step - loss: 0.0504 - val_loss: 0.0430\n",
      "Epoch 5/100\n",
      "64/64 [==============================] - 4s 70ms/step - loss: 0.0508 - val_loss: 0.0453\n",
      "Epoch 6/100\n",
      "64/64 [==============================] - 4s 59ms/step - loss: 0.0507 - val_loss: 0.0519\n",
      "Epoch 7/100\n",
      "64/64 [==============================] - 4s 64ms/step - loss: 0.0511 - val_loss: 0.0440\n",
      "Epoch 8/100\n",
      "64/64 [==============================] - 4s 68ms/step - loss: 0.0509 - val_loss: 0.0430\n",
      "Epoch 9/100\n",
      "64/64 [==============================] - 4s 56ms/step - loss: 0.0502 - val_loss: 0.0409\n",
      "Epoch 10/100\n",
      "64/64 [==============================] - 4s 63ms/step - loss: 0.0505 - val_loss: 0.0416\n",
      "Epoch 11/100\n",
      "64/64 [==============================] - 4s 57ms/step - loss: 0.0495 - val_loss: 0.0414\n",
      "Epoch 12/100\n",
      "64/64 [==============================] - 5s 71ms/step - loss: 0.0500 - val_loss: 0.0405\n",
      "Epoch 13/100\n",
      "64/64 [==============================] - 3s 55ms/step - loss: 0.0493 - val_loss: 0.0431\n",
      "Epoch 14/100\n",
      "64/64 [==============================] - 4s 66ms/step - loss: 0.0500 - val_loss: 0.0428\n",
      "Epoch 15/100\n",
      "64/64 [==============================] - 4s 59ms/step - loss: 0.0494 - val_loss: 0.0421\n",
      "Epoch 16/100\n",
      "64/64 [==============================] - 4s 54ms/step - loss: 0.0499 - val_loss: 0.0438\n",
      "Epoch 17/100\n",
      "64/64 [==============================] - 4s 65ms/step - loss: 0.0485 - val_loss: 0.0412\n",
      "Epoch 18/100\n",
      "64/64 [==============================] - 4s 61ms/step - loss: 0.0486 - val_loss: 0.0448\n",
      "Epoch 19/100\n",
      "64/64 [==============================] - 4s 67ms/step - loss: 0.0484 - val_loss: 0.0408\n",
      "Epoch 20/100\n",
      "64/64 [==============================] - 4s 67ms/step - loss: 0.0477 - val_loss: 0.0431\n",
      "Epoch 21/100\n",
      "64/64 [==============================] - 4s 60ms/step - loss: 0.0483 - val_loss: 0.0430\n",
      "Epoch 22/100\n",
      "64/64 [==============================] - 4s 56ms/step - loss: 0.0478 - val_loss: 0.0456\n",
      "Epoch 23/100\n",
      "64/64 [==============================] - 4s 58ms/step - loss: 0.0496 - val_loss: 0.0406\n",
      "Epoch 24/100\n",
      "64/64 [==============================] - 4s 59ms/step - loss: 0.0471 - val_loss: 0.0439\n",
      "Epoch 25/100\n",
      "64/64 [==============================] - 5s 73ms/step - loss: 0.0475 - val_loss: 0.0407\n",
      "Epoch 26/100\n",
      "64/64 [==============================] - 3s 51ms/step - loss: 0.0480 - val_loss: 0.0396\n",
      "Epoch 27/100\n",
      "64/64 [==============================] - 4s 68ms/step - loss: 0.0474 - val_loss: 0.0396\n",
      "Epoch 28/100\n",
      "64/64 [==============================] - 3s 54ms/step - loss: 0.0475 - val_loss: 0.0408\n",
      "Epoch 29/100\n",
      "64/64 [==============================] - 3s 51ms/step - loss: 0.0473 - val_loss: 0.0435\n",
      "Epoch 30/100\n",
      "64/64 [==============================] - 4s 59ms/step - loss: 0.0457 - val_loss: 0.0418\n",
      "Epoch 31/100\n",
      "64/64 [==============================] - 3s 52ms/step - loss: 0.0457 - val_loss: 0.0430\n",
      "Epoch 32/100\n",
      "64/64 [==============================] - 3s 49ms/step - loss: 0.0460 - val_loss: 0.0417\n",
      "Epoch 33/100\n",
      "64/64 [==============================] - 3s 40ms/step - loss: 0.0451 - val_loss: 0.0406\n",
      "Epoch 34/100\n",
      "64/64 [==============================] - 3s 43ms/step - loss: 0.0444 - val_loss: 0.0412\n",
      "Epoch 35/100\n",
      "64/64 [==============================] - 3s 42ms/step - loss: 0.0454 - val_loss: 0.0414\n",
      "Epoch 36/100\n",
      "64/64 [==============================] - 3s 41ms/step - loss: 0.0444 - val_loss: 0.0435\n",
      "Epoch 37/100\n",
      "64/64 [==============================] - 3s 54ms/step - loss: 0.0447 - val_loss: 0.0397\n",
      "Epoch 38/100\n",
      "64/64 [==============================] - 3s 43ms/step - loss: 0.0429 - val_loss: 0.0427\n",
      "Epoch 39/100\n",
      "64/64 [==============================] - 3s 39ms/step - loss: 0.0428 - val_loss: 0.0406\n",
      "Epoch 40/100\n",
      "64/64 [==============================] - 3s 41ms/step - loss: 0.0434 - val_loss: 0.0419\n",
      "Epoch 41/100\n",
      "64/64 [==============================] - 7s 104ms/step - loss: 0.0427 - val_loss: 0.0417\n",
      "Epoch 42/100\n",
      "64/64 [==============================] - 3s 51ms/step - loss: 0.0414 - val_loss: 0.0409\n",
      "Epoch 43/100\n",
      "64/64 [==============================] - 4s 63ms/step - loss: 0.0418 - val_loss: 0.0399\n",
      "Epoch 44/100\n",
      "64/64 [==============================] - 3s 44ms/step - loss: 0.0412 - val_loss: 0.0379\n",
      "Epoch 45/100\n",
      "64/64 [==============================] - 8s 121ms/step - loss: 0.0408 - val_loss: 0.0395\n",
      "Epoch 46/100\n",
      "64/64 [==============================] - 4s 64ms/step - loss: 0.0412 - val_loss: 0.0428\n",
      "Epoch 47/100\n",
      "64/64 [==============================] - 3s 51ms/step - loss: 0.0405 - val_loss: 0.0420\n",
      "Epoch 48/100\n",
      "64/64 [==============================] - 4s 56ms/step - loss: 0.0409 - val_loss: 0.0398\n",
      "Epoch 49/100\n",
      "64/64 [==============================] - 3s 47ms/step - loss: 0.0390 - val_loss: 0.0392\n",
      "Epoch 50/100\n",
      "64/64 [==============================] - 4s 58ms/step - loss: 0.0376 - val_loss: 0.0368\n",
      "Epoch 51/100\n",
      "64/64 [==============================] - 3s 48ms/step - loss: 0.0374 - val_loss: 0.0377\n",
      "Epoch 52/100\n",
      "64/64 [==============================] - 4s 66ms/step - loss: 0.0362 - val_loss: 0.0393\n",
      "Epoch 53/100\n",
      "64/64 [==============================] - 4s 60ms/step - loss: 0.0349 - val_loss: 0.0395\n",
      "Epoch 54/100\n",
      "64/64 [==============================] - 5s 73ms/step - loss: 0.0343 - val_loss: 0.0368\n",
      "Epoch 55/100\n",
      "64/64 [==============================] - 3s 45ms/step - loss: 0.0332 - val_loss: 0.0365\n",
      "Epoch 56/100\n",
      "64/64 [==============================] - 3s 45ms/step - loss: 0.0335 - val_loss: 0.0360\n",
      "Epoch 57/100\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 0.0327 - val_loss: 0.0423\n",
      "Epoch 58/100\n",
      "64/64 [==============================] - 3s 40ms/step - loss: 0.0312 - val_loss: 0.0298\n",
      "Epoch 59/100\n",
      "64/64 [==============================] - 2s 35ms/step - loss: 0.0300 - val_loss: 0.0310\n",
      "Epoch 60/100\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 0.0286 - val_loss: 0.0293\n",
      "Epoch 61/100\n",
      "64/64 [==============================] - 3s 48ms/step - loss: 0.0306 - val_loss: 0.0310\n",
      "Epoch 62/100\n",
      "64/64 [==============================] - 4s 59ms/step - loss: 0.0283 - val_loss: 0.0369\n",
      "Epoch 63/100\n",
      "64/64 [==============================] - 3s 45ms/step - loss: 0.0275 - val_loss: 0.0309\n",
      "Epoch 64/100\n",
      "64/64 [==============================] - 3s 40ms/step - loss: 0.0275 - val_loss: 0.0309\n",
      "Epoch 65/100\n",
      "64/64 [==============================] - 2s 35ms/step - loss: 0.0285 - val_loss: 0.0367\n",
      "Epoch 66/100\n",
      "64/64 [==============================] - 2s 36ms/step - loss: 0.0281 - val_loss: 0.0329\n",
      "Epoch 67/100\n",
      "64/64 [==============================] - 3s 41ms/step - loss: 0.0269 - val_loss: 0.0319\n",
      "Epoch 68/100\n",
      "64/64 [==============================] - 2s 37ms/step - loss: 0.0275 - val_loss: 0.0312\n",
      "Epoch 69/100\n",
      "64/64 [==============================] - 2s 37ms/step - loss: 0.0371 - val_loss: 0.0339\n",
      "Epoch 70/100\n",
      "64/64 [==============================] - 2s 37ms/step - loss: 0.0265 - val_loss: 0.0281\n",
      "Epoch 71/100\n",
      "64/64 [==============================] - 2s 37ms/step - loss: 0.0385 - val_loss: 0.0498\n",
      "Epoch 72/100\n",
      "64/64 [==============================] - 2s 36ms/step - loss: 0.0610 - val_loss: 0.0411\n",
      "Epoch 73/100\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 0.0534 - val_loss: 0.0408\n",
      "Epoch 74/100\n",
      "64/64 [==============================] - 3s 48ms/step - loss: 0.0517 - val_loss: 0.0419\n",
      "Epoch 75/100\n",
      "64/64 [==============================] - 3s 46ms/step - loss: 0.0521 - val_loss: 0.0405\n",
      "Epoch 76/100\n",
      "64/64 [==============================] - 2s 34ms/step - loss: 0.0507 - val_loss: 0.0410\n",
      "Epoch 77/100\n",
      "64/64 [==============================] - 3s 40ms/step - loss: 0.0505 - val_loss: 0.0400\n",
      "Epoch 78/100\n",
      "64/64 [==============================] - 2s 36ms/step - loss: 0.0501 - val_loss: 0.0439\n",
      "Epoch 79/100\n",
      "64/64 [==============================] - 2s 37ms/step - loss: 0.0519 - val_loss: 0.0406\n",
      "Epoch 80/100\n",
      "64/64 [==============================] - 2s 39ms/step - loss: 0.0499 - val_loss: 0.0406\n",
      "Epoch 81/100\n",
      "64/64 [==============================] - 2s 36ms/step - loss: 0.0502 - val_loss: 0.0492\n",
      "Epoch 82/100\n",
      "64/64 [==============================] - 3s 39ms/step - loss: 0.0507 - val_loss: 0.0405\n",
      "Epoch 83/100\n",
      "64/64 [==============================] - 2s 36ms/step - loss: 0.0499 - val_loss: 0.0468\n",
      "Epoch 84/100\n",
      "64/64 [==============================] - 2s 37ms/step - loss: 0.0507 - val_loss: 0.0413\n",
      "Epoch 85/100\n",
      "64/64 [==============================] - 3s 39ms/step - loss: 0.0501 - val_loss: 0.0419\n",
      "Epoch 86/100\n",
      "64/64 [==============================] - 3s 41ms/step - loss: 0.0493 - val_loss: 0.0428\n",
      "Epoch 87/100\n",
      "64/64 [==============================] - 3s 44ms/step - loss: 0.0492 - val_loss: 0.0405\n",
      "Epoch 88/100\n",
      "64/64 [==============================] - 3s 40ms/step - loss: 0.0490 - val_loss: 0.0438\n",
      "Epoch 89/100\n",
      "64/64 [==============================] - 2s 36ms/step - loss: 0.0493 - val_loss: 0.0411\n",
      "Epoch 90/100\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 0.0507 - val_loss: 0.0413\n",
      "Epoch 91/100\n",
      "64/64 [==============================] - 2s 37ms/step - loss: 0.0503 - val_loss: 0.0406\n",
      "Epoch 92/100\n",
      "64/64 [==============================] - 2s 35ms/step - loss: 0.0505 - val_loss: 0.0424\n",
      "Epoch 93/100\n",
      "64/64 [==============================] - 2s 38ms/step - loss: 0.0501 - val_loss: 0.0407\n",
      "Epoch 94/100\n",
      "64/64 [==============================] - 2s 36ms/step - loss: 0.0508 - val_loss: 0.0420\n",
      "Epoch 95/100\n",
      "64/64 [==============================] - 3s 41ms/step - loss: 0.0503 - val_loss: 0.0404\n",
      "Epoch 96/100\n",
      "64/64 [==============================] - 3s 51ms/step - loss: 0.0505 - val_loss: 0.0404\n",
      "Epoch 97/100\n",
      "64/64 [==============================] - 3s 54ms/step - loss: 0.0504 - val_loss: 0.0409\n",
      "Epoch 98/100\n",
      "64/64 [==============================] - 3s 53ms/step - loss: 0.0501 - val_loss: 0.0414\n",
      "Epoch 99/100\n",
      "64/64 [==============================] - 3s 43ms/step - loss: 0.0497 - val_loss: 0.0399\n",
      "Epoch 100/100\n",
      "64/64 [==============================] - 3s 44ms/step - loss: 0.0500 - val_loss: 0.0399\n"
     ]
    }
   ],
   "source": [
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "\n",
    "history = model.fit(X[:2560], Y[:2560], epochs=100, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train_text = '/Users/seokholee/lsh/study/DL/nsmc-master/nsmc-master/ratings_train.txt'\n",
    "path_test_text = '/Users/seokholee/lsh/study/DL/nsmc-master/nsmc-master/ratings_test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = open(path_train_text, 'rb').read().decode(encoding='utf-8')\n",
    "test_text = open(path_test_text, 'rb').read().decode(encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Y = np.array([[int(row.split('\\t')[2])] for row in train_text.split('\\n')[1:] if row.count('\\t')>0])\n",
    "test_Y = np.array([[int(row.split('\\t')[2])] for row in test_text.split('\\n')[1:] if row.count('\\t')>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "x = [np.nan,1,2,3,4,5]\n",
    "y = pd.Series([x[np.random.randint(0,6)] for i in range(20)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     3.0\n",
       "1     2.0\n",
       "2     3.0\n",
       "3     3.0\n",
       "4     4.0\n",
       "5     4.0\n",
       "6     4.0\n",
       "7     4.0\n",
       "8     3.0\n",
       "9     1.0\n",
       "10    3.0\n",
       "11    1.0\n",
       "12    3.0\n",
       "13    3.0\n",
       "14    3.0\n",
       "15    4.0\n",
       "16    2.0\n",
       "17    3.0\n",
       "18    3.0\n",
       "19    4.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.fillna(y[~y.isna()].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
