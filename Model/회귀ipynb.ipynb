{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 회귀\n",
        "\n",
        "### 개념\n",
        " 　여러 개의 독립변수와 한 개의 종속변수 간의 상관관계를 모델링 하는 기법\n",
        "\n",
        " $${Y = W_1*X_1 + W_2*X_2 + ... + W_n*X_n}$$\n",
        "</br>\n",
        "$Y$ : 종속변수(target)</br>\n",
        "${X_n}$ : 각 독립변수(Feature)</br>\n",
        "${W_n}$ : 각 독립변수의 값에 영향을 미치는 회귀 계수\n",
        "\n",
        "\n",
        "</br></br></br>\n",
        "\n",
        "### 선형 모형과 비선형 모형\n",
        "\n",
        "- 선형 모형</br>\n",
        "　선형모형은 모형식이 모수(파라미터)들의 선형함수로 주어지는 모형을 뜻합니다.\n",
        "\n",
        "![img](https://user-images.githubusercontent.com/119479455/223947355-2e3aaf2d-c28f-4d93-be84-916356161d40.png)\n",
        "\n",
        "</br></br>\n",
        "\n",
        "- 비선형 모형</br>\n",
        "　과학의 여러 분야에서 나타나는 현상들에서는 변수들이 비선형관계로 설명되는 것이 더욱 자연스러운 경우가 많다. 회귀모형에 주어진 회귀식이 모수들의 비선형함수로 나타내어지는 경우 이러한 모형을 비선형회귀모형이라 한다.\n",
        "\n",
        "![img](https://user-images.githubusercontent.com/119479455/223947537-01c7aa5b-a06f-4b0e-8b91-5aa40e7cc021.png)\n",
        "\n",
        "</br></br></br>\n",
        "### M/L\n",
        "\n",
        "- Hypothesis Function(H)</br>\n",
        "　가설 함수, 머신러닝의 목적이 되는 함수\n",
        "  1. 입력 값 X가 출력 값 Y에 영향을 미치는 정도를 의미하는 Weight로 이루어져 있다.\n",
        "  </br></br>\n",
        "  2. 출력 값 Y는 예측 값(label)이다.\n",
        "  </br></br>\n",
        "  3. 입력 값 X는 주어진 데이터이므로 정확한 Hypothesis를 찾는다는 것은 Weight를 정확히 찾아낸다는 것을 의미\n",
        "</br>\n",
        "- Cost Function(J)</br>\n",
        "　Hypothesis Function로 인한 예측값과 실제 값의 차이\n",
        "\n",
        "\n",
        "- 정확한 Hypothesis를 찾는 과정\n",
        "  1. Weight에 임의 값을 초기화하여 예측값을 찾는다.\n",
        "  2. 찾은 첫 번째 예측값과 실제값의 차이를 계산한다.(Cost Function)\n",
        "  3. 실제값과 예측값의 차이를 줄인다.\n",
        "  = Cost Function을 최소화한다.</br>\n",
        "  = 최적의 Weight를 찾는다.\n",
        "  4. Cost 값이 낮아지는 방향으로 Weight 값을 업데이트하고 Cost각 갖아 낮을 때가 최적이라 한다.\n",
        "\n",
        "따라서 머신러닝의 회귀 알고리즘은 **초기 H 함수를 만들고 Cost를 계산, 낮아지는 방향으로 Weight를 업데이트 하면서 최적의 H함수를 찾는 것이다.**\n",
        "</br></br></br>\n",
        "\n",
        "\n",
        "#### 회귀 모델의 문제점\n",
        "- 다항 회귀\n",
        "　데이터의 분포가 직선이 아닌 곡선의 형태를 취하고 있다면 선형회귀모델 사용시 오차가 커질 수밖에 없다. 즉 비선형회귀모델을 사용해야하는 경우가 이 경우이다.\n",
        "\n",
        "　회귀식이 2차, 3차 방정식과 같은 다항식으로 표현되는 것\n",
        "$$Y = {w_0 + w_1x_1 + w_2*x_2+w_3*x_1*x_2+w_4*x_1^2+w_5*x_2^2}$$\n",
        "\n",
        "</br></br>\n",
        "- 과적합(Overfitting), 과소적합(Underfitting)\n",
        "　 쉽게 이야기하면 과적합은 훈련한 것에 대해서는 완벽한 수준으로 대응하지만 훈련과정에 없던게 나오면 예측하지 못하는 것이다. 과소적합은 훈련이 부족해서 훈련과정에도 테스트과정에도 예측이 어려운 상황이다. 그래서 이 두 현상 사이에서 최적의 값을 찾는게 중요하다.\n",
        "\n",
        "![img](https://user-images.githubusercontent.com/119479455/223951881-bd6cd197-8d2c-46cd-bb5d-c8a387f88385.png)\n",
        "</br></br>\n",
        "따라서 모델을 만들때 Validation Error가 최소가 되는 지점에서 훈련을 멈추는게 가장 좋다고 할 수 있다.\n",
        "\n",
        "![img](https://lh5.googleusercontent.com/lAbzDl1HYiYHAEuGnaUw2GdCyQzkZvjWisgNY-ZRYqvRG-X-U7f7cL_UunIF7v5q0BbUSw4CZ-1-xMXs8mvE8fbGa7ghFeEGzuwJ6wiIs64nUgJxkDNEC2JrSTUHEjViRZLdA23NLqI)\n",
        "</br></br>\n",
        "++ 과적합, 과소적합임을 평가하는 지표는 편향(bias)과 분산(variance)인데 모델에서 이 두개의 관계는 Trade-off관계다.\n",
        "\n",
        "![img](https://lh3.googleusercontent.com/rq_iMVSuIK1K4ykF9RQnF05hH6xxWm3lmNPWuQ3hfK9r4-3GBIuCxCW3L7QH53M3EIwbVWOcaRiRLDc0AIJ-0uq8-qzavpSWPceQ1lchq-ZPF16l3KLst24-x6MbGYFqQbEJmEI3gEc)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zS8RXqkPKSia"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3toLuURoOgma"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}